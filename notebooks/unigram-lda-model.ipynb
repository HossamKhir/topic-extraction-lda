{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Topic Extraction w/ Latent Dirichlet Allocation `LDA`\n\n## Fetching dataset & unraring\n","metadata":{"papermill":{"duration":0.060597,"end_time":"2022-04-13T15:13:31.621484","exception":false,"start_time":"2022-04-13T15:13:31.560887","status":"completed"},"tags":[]}},{"cell_type":"code","source":"!wget https://www.minapharm.com/gShare/Pubmed5k.rar \n!apt-get install unrar\n!unrar e Pubmed5k.rar\n","metadata":{"papermill":{"duration":31.23766,"end_time":"2022-04-13T15:14:02.919633","exception":false,"start_time":"2022-04-13T15:13:31.681973","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-13T20:02:54.869861Z","iopub.execute_input":"2022-04-13T20:02:54.870432Z","iopub.status.idle":"2022-04-13T20:03:18.387746Z","shell.execute_reply.started":"2022-04-13T20:02:54.870288Z","shell.execute_reply":"2022-04-13T20:03:18.386861Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"---\n\n## Upgrading modules & fetching required modules\n","metadata":{"papermill":{"duration":0.117239,"end_time":"2022-04-13T15:14:03.148832","exception":false,"start_time":"2022-04-13T15:14:03.031593","status":"completed"},"tags":[]}},{"cell_type":"code","source":"!python3 -m pip install --upgrade pip nltk gensim\n# openpyxl is required by pandas to read_excel\n!python3 -m pip install openpyxl \n","metadata":{"papermill":{"duration":46.341648,"end_time":"2022-04-13T15:14:49.590315","exception":false,"start_time":"2022-04-13T15:14:03.248667","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-13T20:03:18.390477Z","iopub.execute_input":"2022-04-13T20:03:18.390856Z","iopub.status.idle":"2022-04-13T20:03:59.631733Z","shell.execute_reply.started":"2022-04-13T20:03:18.390811Z","shell.execute_reply":"2022-04-13T20:03:59.630664Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Feature Engineering of corpus\n\nThe following resources were found helpful devising a strategy for feature engineering:\n\n- [Text Analysis & Feature Engineering with NLP](https://towardsdatascience.com/text-analysis-feature-engineering-with-nlp-502d6ea9225d)\n- [Topic Modelling and Latent Dirichlet Allocation \\(LDA\\) in Python](https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24)\n\n### Importing modules &amp; defining globals\n","metadata":{"papermill":{"duration":0.132054,"end_time":"2022-04-13T15:14:49.874148","exception":false,"start_time":"2022-04-13T15:14:49.742094","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport nltk\n\nfrom gensim.parsing.preprocessing import STOPWORDS\nfrom nltk.corpus import stopwords\n\nnltk.download(\"omw-1.4\")\nnp.random.seed(42)\n\nDATA_PATH = \"./\"\nSTOPWORDS = STOPWORDS | frozenset(stopwords.words(\"english\"))\n","metadata":{"papermill":{"duration":3.665127,"end_time":"2022-04-13T15:14:53.673060","exception":false,"start_time":"2022-04-13T15:14:50.007933","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-13T20:03:59.634041Z","iopub.execute_input":"2022-04-13T20:03:59.634411Z","iopub.status.idle":"2022-04-13T20:04:02.465748Z","shell.execute_reply.started":"2022-04-13T20:03:59.634354Z","shell.execute_reply":"2022-04-13T20:04:02.464870Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"### Loading dataset\n","metadata":{"papermill":{"duration":0.132147,"end_time":"2022-04-13T15:14:53.938150","exception":false,"start_time":"2022-04-13T15:14:53.806003","status":"completed"},"tags":[]}},{"cell_type":"code","source":"io = \"Pubmed5k.xlsx\"\nsheet_name = \"random 5k\"\ndf = pd.read_excel(os.path.join(DATA_PATH, io), sheet_name=sheet_name, index_col=[0])\ndf.head()\n","metadata":{"papermill":{"duration":1.336372,"end_time":"2022-04-13T15:14:55.410993","exception":false,"start_time":"2022-04-13T15:14:54.074621","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-13T20:04:02.469533Z","iopub.execute_input":"2022-04-13T20:04:02.469824Z","iopub.status.idle":"2022-04-13T20:04:03.532385Z","shell.execute_reply.started":"2022-04-13T20:04:02.469786Z","shell.execute_reply":"2022-04-13T20:04:03.531789Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### Exploring dataset\n","metadata":{"papermill":{"duration":0.133016,"end_time":"2022-04-13T15:14:55.676851","exception":false,"start_time":"2022-04-13T15:14:55.543835","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df_lower = df[\"Abstract\"].str.lower()\n\n# some records have no clear abstract\nidx_no_abs = df_lower.str.find(\"no abstract\") != -1\n\ndf_processed = df[~idx_no_abs]\n","metadata":{"papermill":{"duration":0.18419,"end_time":"2022-04-13T15:14:55.993965","exception":false,"start_time":"2022-04-13T15:14:55.809775","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-13T20:04:03.533479Z","iopub.execute_input":"2022-04-13T20:04:03.533814Z","iopub.status.idle":"2022-04-13T20:04:03.577978Z","shell.execute_reply.started":"2022-04-13T20:04:03.533779Z","shell.execute_reply":"2022-04-13T20:04:03.577081Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df_len = df_processed.apply({\"Title\": len, \"Abstract\": len})\ndf_len.describe()\n","metadata":{"papermill":{"duration":0.169497,"end_time":"2022-04-13T15:14:56.295725","exception":false,"start_time":"2022-04-13T15:14:56.126228","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-13T20:04:03.579624Z","iopub.execute_input":"2022-04-13T20:04:03.579966Z","iopub.status.idle":"2022-04-13T20:04:03.614250Z","shell.execute_reply.started":"2022-04-13T20:04:03.579923Z","shell.execute_reply":"2022-04-13T20:04:03.613312Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"some of the statistics for length of the documents are illogical.\ne.g: min(Abstract) = 1\n","metadata":{"papermill":{"duration":0.133133,"end_time":"2022-04-13T15:14:56.561622","exception":false,"start_time":"2022-04-13T15:14:56.428489","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df_len[\"Abstract\"].value_counts().sort_index().head(10)\n","metadata":{"papermill":{"duration":0.148366,"end_time":"2022-04-13T15:14:56.843095","exception":false,"start_time":"2022-04-13T15:14:56.694729","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-13T20:04:03.615672Z","iopub.execute_input":"2022-04-13T20:04:03.615931Z","iopub.status.idle":"2022-04-13T20:04:03.627625Z","shell.execute_reply.started":"2022-04-13T20:04:03.615900Z","shell.execute_reply":"2022-04-13T20:04:03.626515Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"df_processed[df_len[\"Abstract\"] <= 104][\"Abstract\"]\n","metadata":{"papermill":{"duration":0.147739,"end_time":"2022-04-13T15:14:57.124914","exception":false,"start_time":"2022-04-13T15:14:56.977175","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-13T20:04:03.629380Z","iopub.execute_input":"2022-04-13T20:04:03.629751Z","iopub.status.idle":"2022-04-13T20:04:03.641329Z","shell.execute_reply.started":"2022-04-13T20:04:03.629705Z","shell.execute_reply":"2022-04-13T20:04:03.640533Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df_processed[df_len[\"Abstract\"] == 43][\"Title\"].values\n","metadata":{"papermill":{"duration":0.145926,"end_time":"2022-04-13T15:14:57.406240","exception":false,"start_time":"2022-04-13T15:14:57.260314","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-13T20:04:03.642958Z","iopub.execute_input":"2022-04-13T20:04:03.643454Z","iopub.status.idle":"2022-04-13T20:04:03.652210Z","shell.execute_reply.started":"2022-04-13T20:04:03.643412Z","shell.execute_reply":"2022-04-13T20:04:03.651526Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"df_len[\"Title\"].value_counts().sort_index().head(10)\n","metadata":{"papermill":{"duration":0.146138,"end_time":"2022-04-13T15:14:57.687018","exception":false,"start_time":"2022-04-13T15:14:57.540880","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-13T20:04:03.655089Z","iopub.execute_input":"2022-04-13T20:04:03.655881Z","iopub.status.idle":"2022-04-13T20:04:03.667134Z","shell.execute_reply.started":"2022-04-13T20:04:03.655838Z","shell.execute_reply":"2022-04-13T20:04:03.666063Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"df_processed[df_len[\"Title\"] <= 31][\"Title\"]\n","metadata":{"papermill":{"duration":0.148885,"end_time":"2022-04-13T15:14:57.971556","exception":false,"start_time":"2022-04-13T15:14:57.822671","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-13T20:04:03.668634Z","iopub.execute_input":"2022-04-13T20:04:03.669664Z","iopub.status.idle":"2022-04-13T20:04:03.683522Z","shell.execute_reply.started":"2022-04-13T20:04:03.669621Z","shell.execute_reply":"2022-04-13T20:04:03.682722Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"df_altered = df[idx_no_abs]\ndf_altered = pd.concat([df_altered, df_processed[df_len[\"Abstract\"] <= 43]])\ndf_altered.loc[:, \"Abstract\"] = \"\"\ndf_altered.shape\n","metadata":{"papermill":{"duration":0.158937,"end_time":"2022-04-13T15:14:58.288268","exception":false,"start_time":"2022-04-13T15:14:58.129331","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-13T20:04:03.685446Z","iopub.execute_input":"2022-04-13T20:04:03.685861Z","iopub.status.idle":"2022-04-13T20:04:03.699105Z","shell.execute_reply.started":"2022-04-13T20:04:03.685814Z","shell.execute_reply":"2022-04-13T20:04:03.698277Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"df_altered.head()\n","metadata":{"papermill":{"duration":0.158592,"end_time":"2022-04-13T15:14:58.583749","exception":false,"start_time":"2022-04-13T15:14:58.425157","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-13T20:04:03.700524Z","iopub.execute_input":"2022-04-13T20:04:03.701188Z","iopub.status.idle":"2022-04-13T20:04:03.713294Z","shell.execute_reply.started":"2022-04-13T20:04:03.701158Z","shell.execute_reply":"2022-04-13T20:04:03.712108Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"df_processed = df.drop(index=df_altered.index)\ndf_processed = pd.concat([df_processed, df_altered])\ndf_processed.shape\n","metadata":{"papermill":{"duration":0.165935,"end_time":"2022-04-13T15:14:58.893230","exception":false,"start_time":"2022-04-13T15:14:58.727295","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-13T20:04:03.715339Z","iopub.execute_input":"2022-04-13T20:04:03.716000Z","iopub.status.idle":"2022-04-13T20:04:03.727248Z","shell.execute_reply.started":"2022-04-13T20:04:03.715952Z","shell.execute_reply":"2022-04-13T20:04:03.726178Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"### Preprocessing\n\n> Note: the approaches here are for a unigram model.\n\nafter exploring the dataset, and slightly tweaking some features, the two columns of the set are joined to make a single feature (document per record) to be able to operate on the dataset\n","metadata":{"papermill":{"duration":0.147381,"end_time":"2022-04-13T15:14:59.189240","exception":false,"start_time":"2022-04-13T15:14:59.041859","status":"completed"},"tags":[]}},{"cell_type":"code","source":"corpus = df_processed[\"Title\"] + r\" \" + df_processed[\"Abstract\"]\ncorpus.name = \"document\"\ncorpus.head()\n","metadata":{"papermill":{"duration":0.173777,"end_time":"2022-04-13T15:14:59.518039","exception":false,"start_time":"2022-04-13T15:14:59.344262","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-13T20:04:03.728852Z","iopub.execute_input":"2022-04-13T20:04:03.729483Z","iopub.status.idle":"2022-04-13T20:04:03.748294Z","shell.execute_reply.started":"2022-04-13T20:04:03.729435Z","shell.execute_reply":"2022-04-13T20:04:03.747673Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"Defining helper function. Basically, bundling the preprocess subroutine into a function\n\nFor each document:\n\n1. Tokenising the document.\n2. lowercasing the tokens.\n3. lemmatising the tokens.\n4. dropping stop words.\n","metadata":{"papermill":{"duration":0.137721,"end_time":"2022-04-13T15:14:59.803436","exception":false,"start_time":"2022-04-13T15:14:59.665715","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from typing import Union\n\nfrom gensim.utils import simple_preprocess\nfrom nltk.stem import WordNetLemmatizer\n\n\ndef preprocess(\n    document: str,\n    min_len: int = 2,\n    max_len: int = 15,\n    stopwords: frozenset = frozenset(),\n    pos: Union[str, list] = \"n\",\n) -> str:\n    \"\"\"Tokenise the document, drop stopwords, then lowercase and lemmatise\n    each token\n\n    Parameters:\n    -----------\n\n    Returns:\n    --------\n\n    TODO: complete the pydoc\n    \"\"\"\n    # using gensim.utils.simple_preprocess to tokenise, lowercase a document\n    pp_doc = simple_preprocess(document, min_len=min_len, max_len=max_len, deacc=True)\n    # removing generic stopwords from the tokens\n    doc_non_stop = [token for token in pp_doc if token not in stopwords]\n\n    # applying text normalisation: lemmatisation\n    lemmatise = WordNetLemmatizer().lemmatize\n    if type(pos) == str:\n        return [lemmatise(token, pos=pos) for token in doc_non_stop]\n    else:\n        result = doc_non_stop\n        for p in pos:\n            result = [lemmatise(token, pos=p) for token in result]\n        return result\n","metadata":{"papermill":{"duration":0.156836,"end_time":"2022-04-13T15:15:00.099309","exception":false,"start_time":"2022-04-13T15:14:59.942473","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-13T20:04:03.749676Z","iopub.execute_input":"2022-04-13T20:04:03.750196Z","iopub.status.idle":"2022-04-13T20:04:03.759528Z","shell.execute_reply.started":"2022-04-13T20:04:03.750162Z","shell.execute_reply":"2022-04-13T20:04:03.758934Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"- Calling the preprocessing subroutine on the dataset\n","metadata":{"papermill":{"duration":0.13796,"end_time":"2022-04-13T15:15:00.375380","exception":false,"start_time":"2022-04-13T15:15:00.237420","status":"completed"},"tags":[]}},{"cell_type":"code","source":"pos = [\"a\", \"n\", \"r\", \"s\", \"v\"]\ncorpus_processed = corpus.apply(preprocess, stopwords=STOPWORDS, pos=pos)\ncorpus_processed.head()\n","metadata":{"papermill":{"duration":22.914211,"end_time":"2022-04-13T15:15:23.426333","exception":false,"start_time":"2022-04-13T15:15:00.512122","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-13T20:04:03.761885Z","iopub.execute_input":"2022-04-13T20:04:03.762385Z","iopub.status.idle":"2022-04-13T20:04:25.627867Z","shell.execute_reply.started":"2022-04-13T20:04:03.762345Z","shell.execute_reply":"2022-04-13T20:04:25.626983Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"### Saving the final feature engineered dataset\n","metadata":{"papermill":{"duration":0.137188,"end_time":"2022-04-13T15:15:23.701792","exception":false,"start_time":"2022-04-13T15:15:23.564604","status":"completed"},"tags":[]}},{"cell_type":"code","source":"corpus_processed.to_csv(os.path.join(DATA_PATH, \"corpus_clean.csv\"))\n","metadata":{"papermill":{"duration":0.578593,"end_time":"2022-04-13T15:15:24.421479","exception":false,"start_time":"2022-04-13T15:15:23.842886","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-13T20:04:25.629121Z","iopub.execute_input":"2022-04-13T20:04:25.629498Z","iopub.status.idle":"2022-04-13T20:04:26.025767Z","shell.execute_reply.started":"2022-04-13T20:04:25.629463Z","shell.execute_reply":"2022-04-13T20:04:26.024996Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## Hyper-Parameter Tuning\n\n> NOTE: a unigram model is the current considered option\n\nOn using Latent Dirichlet Allocation `LDA`, the most important hyperparameters are:\n\n- **k**: The number of topics.\n- **&alpha;**: the Dirichlet prior for document/topic distribution.\n- **&eta;**: the Dirichlet prior for topic/word distribution.\n\n[Gensim](https://radimrehurek.com/gensim/index.html)'s implementation of `LDA` will be used.\nSpecifically the multi-cored variant [LdaMulticore](https://radimrehurek.com/gensim/models/ldamulticore.html)\n\nThese resources were found helpful for approaching the tuning routine.\n\n- [When Coherence Score is Good or Bad in Topic Modelling?](https://www.baeldung.com/cs/topic-modeling-coherence-score)\n- [Evaluate Topic Models: Latent Dirichlet Allocation (LDA)](https://towardsdatascience.com/evaluate-topic-model-in-python-latent-dirichlet-allocation-lda-7d57484bb5d0)\n\n---\n\n### Importing required modules and setting up globals\n","metadata":{"papermill":{"duration":0.141064,"end_time":"2022-04-13T15:15:24.701888","exception":false,"start_time":"2022-04-13T15:15:24.560824","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import pickle\nimport matplotlib.pyplot as plt\n\nfrom gensim.corpora import Dictionary\nfrom gensim.models import LdaMulticore, CoherenceModel\nfrom pylab import rcParams\n\nrcParams[\"figure.figsize\"] = (16, 9)\nplt.style.use(\"ggplot\")\n","metadata":{"papermill":{"duration":0.152799,"end_time":"2022-04-13T15:15:24.991554","exception":false,"start_time":"2022-04-13T15:15:24.838755","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-13T20:04:26.027061Z","iopub.execute_input":"2022-04-13T20:04:26.027752Z","iopub.status.idle":"2022-04-13T20:04:26.037577Z","shell.execute_reply.started":"2022-04-13T20:04:26.027711Z","shell.execute_reply":"2022-04-13T20:04:26.036952Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"corpus = corpus_processed\n","metadata":{"papermill":{"duration":0.14456,"end_time":"2022-04-13T15:15:25.273133","exception":false,"start_time":"2022-04-13T15:15:25.128573","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-13T20:04:26.038850Z","iopub.execute_input":"2022-04-13T20:04:26.039819Z","iopub.status.idle":"2022-04-13T20:04:26.045537Z","shell.execute_reply.started":"2022-04-13T20:04:26.039761Z","shell.execute_reply":"2022-04-13T20:04:26.044663Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"## Tuning subroutines\n\nFirst, elbow method is used to tune **k**.\n**&alpha;** &amp; **&eta;** are considered optimal, then different **k** topics are fit, then plotted.\n\n---\n\n`LdaMulticore` accepts certain parameters, so we build them first:\n\n- A dictionary of words. Basically a map assigning each word in the available vocabulary an id.\n- A Bag-of-Words `BoW`, that can be easily built from the dictionary\n\n> also the dictionary provides useful utilities, like the ability to drop tokens that appear too little or too much in our corpus; as that might indicate they're less significant than other tokens.\n","metadata":{"papermill":{"duration":0.136196,"end_time":"2022-04-13T15:15:25.546247","exception":false,"start_time":"2022-04-13T15:15:25.410051","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# build the mapping\nid2word = Dictionary(corpus)\n\n# removing tokens that appear in less that 1% (.01) or in more than 50% (.5) of the corpus\nid2word.filter_extremes(0.01 * len(corpus), 0.5, None)\n\n# build a BoW\nbow = corpus.apply(id2word.doc2bow)\n","metadata":{"papermill":{"duration":1.924418,"end_time":"2022-04-13T15:15:27.607863","exception":false,"start_time":"2022-04-13T15:15:25.683445","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-13T20:04:26.046942Z","iopub.execute_input":"2022-04-13T20:04:26.047159Z","iopub.status.idle":"2022-04-13T20:04:27.608433Z","shell.execute_reply.started":"2022-04-13T20:04:26.047134Z","shell.execute_reply":"2022-04-13T20:04:27.607613Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"### Saving objects\n","metadata":{"papermill":{"duration":0.138402,"end_time":"2022-04-13T15:15:27.886361","exception":false,"start_time":"2022-04-13T15:15:27.747959","status":"completed"},"tags":[]}},{"cell_type":"code","source":"pickle_path = \"./\"\nobjects = {\"id2word\": id2word, \"bow\": bow}\n\nfor key, val in objects.items():\n    path = os.path.join(pickle_path, f\"{key}.pkl\")\n    file_ref = open(path, \"wb\")\n    pickle.dump(val, file_ref)\n    file_ref.close()\n","metadata":{"papermill":{"duration":0.290798,"end_time":"2022-04-13T15:15:28.317793","exception":false,"start_time":"2022-04-13T15:15:28.026995","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-13T20:04:27.609739Z","iopub.execute_input":"2022-04-13T20:04:27.609983Z","iopub.status.idle":"2022-04-13T20:04:27.727474Z","shell.execute_reply.started":"2022-04-13T20:04:27.609949Z","shell.execute_reply":"2022-04-13T20:04:27.726528Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"Now, an `LdaMulticore` model may be built.\n\nThe following resources were found useful to selecting &alpha; &amp; &eta;:\n\n- [What are typical values to use for alpha and beta in Latent Dirichlet Allocation?](https://stats.stackexchange.com/questions/59684/what-are-typical-values-to-use-for-alpha-and-beta-in-latent-dirichlet-allocation)\n- [Rules to set hyper-parameters alpha and theta in LDA model](https://stackoverflow.com/questions/39644667/rules-to-set-hyper-parameters-alpha-and-theta-in-lda-model)\n\n> NOTE: keeping the range of possible **k** at 20 for simplicity and ease of calculation\n\n---\n\n### Tuning **k**\n\nCalculating coherence score on **k** in range \\[3,20\\]\n","metadata":{"papermill":{"duration":0.137692,"end_time":"2022-04-13T15:15:28.597339","exception":false,"start_time":"2022-04-13T15:15:28.459647","status":"completed"},"tags":[]}},{"cell_type":"code","source":"n_co_scores = []\nfor n in range(3, 21):\n    lda_model = LdaMulticore(\n        bow,\n        id2word=id2word,\n        num_topics=n,\n        random_state=42,\n        alpha=\"asymmetric\",\n        eta=\"auto\",\n    )\n    co_model = CoherenceModel(\n        model=lda_model, texts=corpus, dictionary=id2word, coherence=\"u_mass\"\n    )\n    n_co_scores.append((n, co_model.get_coherence()))\n","metadata":{"papermill":{"duration":108.014791,"end_time":"2022-04-13T15:17:16.750605","exception":false,"start_time":"2022-04-13T15:15:28.735814","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-13T20:04:27.728951Z","iopub.execute_input":"2022-04-13T20:04:27.729392Z","iopub.status.idle":"2022-04-13T20:06:11.386680Z","shell.execute_reply.started":"2022-04-13T20:04:27.729360Z","shell.execute_reply":"2022-04-13T20:06:11.385657Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"- Plotting the findings, to look for _elbow_ in graph\n","metadata":{"papermill":{"duration":0.139825,"end_time":"2022-04-13T15:17:17.030320","exception":false,"start_time":"2022-04-13T15:17:16.890495","status":"completed"},"tags":[]}},{"cell_type":"code","source":"x, y = np.array(n_co_scores).T\nplt.plot(x, y)\nplt.xticks(x)\nplt.grid(True)\nplt.show()\n","metadata":{"papermill":{"duration":0.464379,"end_time":"2022-04-13T15:17:17.635636","exception":false,"start_time":"2022-04-13T15:17:17.171257","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-13T20:06:11.388345Z","iopub.execute_input":"2022-04-13T20:06:11.388691Z","iopub.status.idle":"2022-04-13T20:06:11.704075Z","shell.execute_reply.started":"2022-04-13T20:06:11.388651Z","shell.execute_reply":"2022-04-13T20:06:11.703288Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"From the graph: best **k** is at $7$\n\n<!-- , followed by $11$ -->\n\n<!-- > NOTE: choosing $11$ to avoid future mishap, as selecting $3$ yields more documents w/ less than $3$ topic participation -->\n\n---\n\nDue to implementation specifics, `LdaMulticore` doesn't allow using `auto` for &alpha; in constructor. So &alpha; would need to be tuned in a similar fashion.\n\nSetting &eta; to `auto` allows the model to also learn that hyperparameter\n\n### Tuning &alpha;\n","metadata":{"papermill":{"duration":0.145436,"end_time":"2022-04-13T15:17:17.920698","exception":false,"start_time":"2022-04-13T15:17:17.775262","status":"completed"},"tags":[]}},{"cell_type":"code","source":"n = 7\na_co_scores = []\n\nfor a in np.linspace(0.01, 1):\n    lda_model = LdaMulticore(\n        bow,\n        id2word=id2word,\n        num_topics=n,\n        random_state=42,\n        alpha=a,\n        eta=\"auto\",  # lets the model learn that hyperparameter\n    )\n    co_model = CoherenceModel(\n        model=lda_model, texts=corpus, dictionary=id2word, coherence=\"u_mass\"\n    )\n    a_co_scores.append((a, co_model.get_coherence()))\n","metadata":{"papermill":{"duration":309.25963,"end_time":"2022-04-13T15:22:27.322518","exception":false,"start_time":"2022-04-13T15:17:18.062888","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-13T20:06:11.705734Z","iopub.execute_input":"2022-04-13T20:06:11.706287Z","iopub.status.idle":"2022-04-13T20:11:05.354420Z","shell.execute_reply.started":"2022-04-13T20:06:11.706243Z","shell.execute_reply":"2022-04-13T20:11:05.353228Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"Selecting the &alpha; w/ highest coherence score\n","metadata":{"papermill":{"duration":0.139736,"end_time":"2022-04-13T15:22:27.610764","exception":false,"start_time":"2022-04-13T15:22:27.471028","status":"completed"},"tags":[]}},{"cell_type":"code","source":"a_co_scores = sorted(a_co_scores, key=(lambda tup: tup[1]))\na = a_co_scores[-1][0]\n","metadata":{"papermill":{"duration":0.149816,"end_time":"2022-04-13T15:22:27.900045","exception":false,"start_time":"2022-04-13T15:22:27.750229","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-13T20:11:05.356532Z","iopub.execute_input":"2022-04-13T20:11:05.356832Z","iopub.status.idle":"2022-04-13T20:11:05.362816Z","shell.execute_reply.started":"2022-04-13T20:11:05.356797Z","shell.execute_reply":"2022-04-13T20:11:05.361925Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"### Saving findings\n","metadata":{"papermill":{"duration":0.138845,"end_time":"2022-04-13T15:22:28.182816","exception":false,"start_time":"2022-04-13T15:22:28.043971","status":"completed"},"tags":[]}},{"cell_type":"code","source":"hyperparameters = np.array([n, a], dtype=float)\nnp.save(os.path.join(DATA_PATH, \"hyperparameters.npy\"), hyperparameters)\n","metadata":{"papermill":{"duration":0.148093,"end_time":"2022-04-13T15:22:28.470747","exception":false,"start_time":"2022-04-13T15:22:28.322654","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-13T20:11:05.364504Z","iopub.execute_input":"2022-04-13T20:11:05.365042Z","iopub.status.idle":"2022-04-13T20:11:05.376023Z","shell.execute_reply.started":"2022-04-13T20:11:05.364997Z","shell.execute_reply":"2022-04-13T20:11:05.375281Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"## Training a Unigram `LdaMulticore` model\n","metadata":{"papermill":{"duration":0.138799,"end_time":"2022-04-13T15:22:28.748632","exception":false,"start_time":"2022-04-13T15:22:28.609833","status":"completed"},"tags":[]}},{"cell_type":"code","source":"k = n\nlda_model = LdaMulticore(\n    bow,\n    num_topics=k,\n    id2word=id2word,\n    eta=\"auto\",\n    alpha=a,\n    random_state=42,\n)\n","metadata":{"papermill":{"duration":5.37737,"end_time":"2022-04-13T15:22:34.584214","exception":false,"start_time":"2022-04-13T15:22:29.206844","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-13T20:11:05.382132Z","iopub.execute_input":"2022-04-13T20:11:05.382759Z","iopub.status.idle":"2022-04-13T20:11:10.419829Z","shell.execute_reply.started":"2022-04-13T20:11:05.382702Z","shell.execute_reply":"2022-04-13T20:11:10.418620Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"Defining a helper function to wrap the subroutine for selecting top _n_ topics\n","metadata":{"papermill":{"duration":0.141276,"end_time":"2022-04-13T15:22:34.865511","exception":false,"start_time":"2022-04-13T15:22:34.724235","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def get_top_n_topics(\n    corpus: pd.DataFrame, model: LdaMulticore, n: int = 3\n) -> pd.DataFrame:\n    \"\"\"calculates the top `n` topics for each document in `df` through the model\n\n    Parameters:\n    -----------\n\n    Returns:\n    --------\n\n    TODO: complete the pydoc\n    \"\"\"\n    df_lda = corpus.apply(\n        lambda doc: sorted(model[doc], key=(lambda tup: tup[1]), reverse=True)[:n]\n    )\n    corpus = pd.DataFrame(corpus)\n\n    for i in range(n):\n        corpus[f\"topic_{i+1}\"] = df_lda.apply(\n            lambda topics: topics[i][0] if len(topics) > i else None\n        )\n        corpus[f\"topic_{i+1}_prop\"] = df_lda.apply(\n            lambda topics: topics[i][1] if len(topics) > i else None\n        )\n\n    # FIXME: some documents might have less than `n` possible topics\n    # to avoid N/As, set them to the previous topic\n    for i in range(2, n + 1):\n        idx = corpus[f\"topic_{i}\"].isna()\n        cols = [f\"topic_{i}\", f\"topic_{i}_prop\"]\n        cols_prev = [f\"topic_{i-1}\", f\"topic_{i-1}_prop\"]\n        corpus.loc[idx, cols] = corpus.loc[idx, cols_prev].values\n\n    return corpus.drop(columns=[\"document\"])\n","metadata":{"papermill":{"duration":0.156565,"end_time":"2022-04-13T15:22:35.163005","exception":false,"start_time":"2022-04-13T15:22:35.006440","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-13T20:11:10.421618Z","iopub.execute_input":"2022-04-13T20:11:10.422428Z","iopub.status.idle":"2022-04-13T20:11:10.432956Z","shell.execute_reply.started":"2022-04-13T20:11:10.422389Z","shell.execute_reply":"2022-04-13T20:11:10.432268Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"## Assigning topics\n\nnow we use the model to assign topics to records/docs/articles\n","metadata":{"papermill":{"duration":0.138325,"end_time":"2022-04-13T15:22:35.440232","exception":false,"start_time":"2022-04-13T15:22:35.301907","status":"completed"},"tags":[]}},{"cell_type":"code","source":"n = 3\n\ndf_topics = get_top_n_topics(bow, lda_model, n)\ncolumns = [\"topic_1\", \"topic_2\", \"topic_3\"]\ndf_topics[columns] = df_topics[columns].astype(int)\ndf_topics.head()\n","metadata":{"papermill":{"duration":5.504114,"end_time":"2022-04-13T15:22:41.083978","exception":false,"start_time":"2022-04-13T15:22:35.579864","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-13T20:11:10.434043Z","iopub.execute_input":"2022-04-13T20:11:10.434384Z","iopub.status.idle":"2022-04-13T20:11:15.891100Z","shell.execute_reply.started":"2022-04-13T20:11:10.434354Z","shell.execute_reply":"2022-04-13T20:11:15.890224Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"### Saving findings\n","metadata":{"papermill":{"duration":0.139269,"end_time":"2022-04-13T15:22:41.366719","exception":false,"start_time":"2022-04-13T15:22:41.227450","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df_topics.to_csv(os.path.join(DATA_PATH, \"topics.csv\"))\n","metadata":{"papermill":{"duration":0.190328,"end_time":"2022-04-13T15:22:41.697792","exception":false,"start_time":"2022-04-13T15:22:41.507464","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-13T20:11:15.892531Z","iopub.execute_input":"2022-04-13T20:11:15.893153Z","iopub.status.idle":"2022-04-13T20:11:15.940554Z","shell.execute_reply.started":"2022-04-13T20:11:15.893115Z","shell.execute_reply":"2022-04-13T20:11:15.939571Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"## Evaluating model\n","metadata":{"papermill":{"duration":0.140582,"end_time":"2022-04-13T15:22:41.983587","exception":false,"start_time":"2022-04-13T15:22:41.843005","status":"completed"},"tags":[]}},{"cell_type":"code","source":"co_model = CoherenceModel(\n    lda_model, texts=corpus, dictionary=id2word, coherence=\"u_mass\"\n)\nco_model.get_coherence()\n","metadata":{"papermill":{"duration":0.771366,"end_time":"2022-04-13T15:22:42.896057","exception":false,"start_time":"2022-04-13T15:22:42.124691","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-13T20:11:15.941849Z","iopub.execute_input":"2022-04-13T20:11:15.942214Z","iopub.status.idle":"2022-04-13T20:11:16.571737Z","shell.execute_reply.started":"2022-04-13T20:11:15.942182Z","shell.execute_reply":"2022-04-13T20:11:16.570737Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"## Saving the model\n","metadata":{}},{"cell_type":"code","source":"path = os.path.join(DATA_PATH, \"lda_model.pkl\")\nlda_model.save(path)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-13T20:11:16.573040Z","iopub.execute_input":"2022-04-13T20:11:16.573280Z","iopub.status.idle":"2022-04-13T20:11:16.582551Z","shell.execute_reply.started":"2022-04-13T20:11:16.573250Z","shell.execute_reply":"2022-04-13T20:11:16.581783Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"## Naming the topics\n\nAccording to [Luis Serrano](https://ca.linkedin.com/in/luisgserrano) in this [video](https://www.youtube.com/watch?v=T05t-SqKArY);\nlabeling/naming a topic is a task that is best done by humans.\n\nA naive approach would be:\n\n    the name of the topic would be included in the title of the articles.\n\n<!-- here is a simple hack to try using ML for the topic name. -->\n\n<!-- Exploiting TF-IDF, for each topic, the lower the IDF score of a token, the more it appears in documents; intuitively the higher the chance that this particular token is the name of the topic. -->\n\nso we gather the top contributing words per topic, across all topics.\n","metadata":{"papermill":{"duration":0.140748,"end_time":"2022-04-13T15:22:43.177903","exception":false,"start_time":"2022-04-13T15:22:43.037155","status":"completed"},"tags":[]}},{"cell_type":"code","source":"topics_word = lda_model.show_topics(formatted=False)\ntopics_word\n","metadata":{"papermill":{"duration":0.157128,"end_time":"2022-04-13T15:22:43.475645","exception":false,"start_time":"2022-04-13T15:22:43.318517","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-13T20:11:16.584109Z","iopub.execute_input":"2022-04-13T20:11:16.584323Z","iopub.status.idle":"2022-04-13T20:11:16.604631Z","shell.execute_reply.started":"2022-04-13T20:11:16.584297Z","shell.execute_reply":"2022-04-13T20:11:16.604003Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"ignoring for a moment the participation ratio of the tokens\n","metadata":{"papermill":{"duration":0.140567,"end_time":"2022-04-13T15:22:43.759335","exception":false,"start_time":"2022-04-13T15:22:43.618768","status":"completed"},"tags":[]}},{"cell_type":"code","source":"k = len(topics_word)\ntopic_word_sets = [set(np.array(topics_word[i][1])[:, 0]) for i in range(k)]\ntopic_word_sets\n","metadata":{"papermill":{"duration":0.154561,"end_time":"2022-04-13T15:22:44.057307","exception":false,"start_time":"2022-04-13T15:22:43.902746","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-13T20:11:16.606001Z","iopub.execute_input":"2022-04-13T20:11:16.606422Z","iopub.status.idle":"2022-04-13T20:11:16.615398Z","shell.execute_reply.started":"2022-04-13T20:11:16.606389Z","shell.execute_reply":"2022-04-13T20:11:16.614743Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"intersection = topic_word_sets[0]\nfor tw_set in topic_word_sets[1:]:\n    intersection &= tw_set\n\nintersection\n","metadata":{"papermill":{"duration":0.159285,"end_time":"2022-04-13T15:22:44.362952","exception":false,"start_time":"2022-04-13T15:22:44.203667","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-13T20:11:16.616776Z","iopub.execute_input":"2022-04-13T20:11:16.617143Z","iopub.status.idle":"2022-04-13T20:11:16.624663Z","shell.execute_reply.started":"2022-04-13T20:11:16.617114Z","shell.execute_reply":"2022-04-13T20:11:16.624004Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"seems like some words already highly contribute to the entire set of topics of $7$.\n\n\\[high, patient\\]\n\n---\n\nlet's try to obtain unique terms per topic, i.e. the tokens that belong to at most $1$ topic\n\nto do that; we need to filter the sets:\n\nfor each topic:\n\n- make a union\n  of each set of topic/words,\n  not including the current topic\n","metadata":{"papermill":{"duration":0.142678,"end_time":"2022-04-13T15:22:44.659621","exception":false,"start_time":"2022-04-13T15:22:44.516943","status":"completed"},"tags":[]}},{"cell_type":"code","source":"union = [\n    set.union(\n        *[\n            topic_word_sets[i]\n            for i in range(k)  # 3. of each set of topic/words\n            if i != j  # 4. not including the current topic\n        ]\n    )  # 2. make a union\n    for j in range(k)  # 1. for each topic\n]\nunion\n","metadata":{"papermill":{"duration":0.167689,"end_time":"2022-04-13T15:22:44.971651","exception":false,"start_time":"2022-04-13T15:22:44.803962","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-13T20:11:16.626139Z","iopub.execute_input":"2022-04-13T20:11:16.626898Z","iopub.status.idle":"2022-04-13T20:11:16.645195Z","shell.execute_reply.started":"2022-04-13T20:11:16.626856Z","shell.execute_reply":"2022-04-13T20:11:16.644334Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"now, for each topic/words set, get the difference between the set and the complementing union\n","metadata":{"papermill":{"duration":0.143948,"end_time":"2022-04-13T15:22:45.266391","exception":false,"start_time":"2022-04-13T15:22:45.122443","status":"completed"},"tags":[]}},{"cell_type":"code","source":"unique_topic_word = [topic_word_sets[i] - union[i] for i in range(k)]\nunique_topic_word\n","metadata":{"papermill":{"duration":0.155529,"end_time":"2022-04-13T15:22:45.565692","exception":false,"start_time":"2022-04-13T15:22:45.410163","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-13T20:11:16.646881Z","iopub.execute_input":"2022-04-13T20:11:16.647395Z","iopub.status.idle":"2022-04-13T20:11:16.659802Z","shell.execute_reply.started":"2022-04-13T20:11:16.647351Z","shell.execute_reply":"2022-04-13T20:11:16.659135Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"The notice here is that the results contain empty sets. One intuition would be:\n\n    the vocab is built on a unigram model, and topics could likely be a polygram\n\nThe same naive approach could be extended in many ways, e.g:\n\n1. Relying on more than top $10$ words; that might yield non-empty sets, but could equally likely increase the empty sets.\n1. Building a polygram \\(bigram, trigram, ...\\) models, and applying the same naive approach.\n\n---\n\nApart from that caveat, it seems the approach gives acceptable insights into what some of the topics are:\n\n- topic \\#$1$ could be about `treatment`s\n- topic \\#$4$ could be about `cancer`\n- topic \\#$6$ could be about `protein`s\n\nother result don't seem particularly informative:\n\n- topic \\#$2$ could be about `control`, `effect`, `risk`, or a combination of any two of them, or the three of them.\n  perhaps the contribution rates of them could draw another conclusion.\n- topic \\#$5$ have values `low` &amp; `report` which neither can be highly descriptive.\n","metadata":{"papermill":{"duration":0.144389,"end_time":"2022-04-13T15:22:45.852259","exception":false,"start_time":"2022-04-13T15:22:45.707870","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# looking at participation of words in topic 2\n_, topic_2_words = topics_word[2]\nunique_participants = [\n    topic_2_words[i]\n    for i in range(len(topic_2_words))\n    if topic_2_words[i][0] in unique_topic_word[2]\n]\nunique_participants\n","metadata":{"papermill":{"duration":0.15502,"end_time":"2022-04-13T15:22:46.150941","exception":false,"start_time":"2022-04-13T15:22:45.995921","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-13T20:11:16.660942Z","iopub.execute_input":"2022-04-13T20:11:16.661534Z","iopub.status.idle":"2022-04-13T20:11:16.672459Z","shell.execute_reply.started":"2022-04-13T20:11:16.661498Z","shell.execute_reply":"2022-04-13T20:11:16.671505Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"The participation rates merely sorts the findings, as the differences between them are in the $10^{-3}$ range.\n\nHere a bigram model could be helpful, where it could be seen how each pair of them appear, the topic name might be something like:\n\n- `risk control`\n- `risk effect`\n- `control effect`, maybe?\n- ...\n\nOr a trigram model:\n\n- `control risk effect`\n- `effect` _of_ `risk control`\n- ...\n","metadata":{"papermill":{"duration":0.146028,"end_time":"2022-04-13T15:22:46.442123","exception":false,"start_time":"2022-04-13T15:22:46.296095","status":"completed"},"tags":[]}},{"cell_type":"code","source":"topic_dict = {\n    1: \"treatment\",\n    4: \"cancer\",\n    6: \"protein\",\n    2: \"effect\",  # selected by order of participation\n    5: \"report\",  # selected intuitively as report could be more meaningful than low\n    # randomly selecting remaining topic names from participants\n    0: \"covid\",\n    3: \"specie\",\n}\ncolumns = [\"topic_1\", \"topic_2\", \"topic_3\"]\ndf_topics.loc[:, columns] = df_topics[columns].replace(topic_dict).values\ndf_topics.head()\n","metadata":{"papermill":{"duration":0.169343,"end_time":"2022-04-13T15:22:46.755327","exception":false,"start_time":"2022-04-13T15:22:46.585984","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-13T20:20:04.334604Z","iopub.execute_input":"2022-04-13T20:20:04.336188Z","iopub.status.idle":"2022-04-13T20:20:04.371277Z","shell.execute_reply.started":"2022-04-13T20:20:04.336123Z","shell.execute_reply":"2022-04-13T20:20:04.370500Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"### Saving findings\n","metadata":{"papermill":{"duration":0.144659,"end_time":"2022-04-13T15:22:47.047805","exception":false,"start_time":"2022-04-13T15:22:46.903146","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df_topics.to_csv(os.path.join(DATA_PATH, \"topics_named.csv\"))\n","metadata":{"papermill":{"duration":0.196393,"end_time":"2022-04-13T15:22:47.388244","exception":false,"start_time":"2022-04-13T15:22:47.191851","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-13T20:20:07.960802Z","iopub.execute_input":"2022-04-13T20:20:07.962247Z","iopub.status.idle":"2022-04-13T20:20:08.016151Z","shell.execute_reply.started":"2022-04-13T20:20:07.962187Z","shell.execute_reply":"2022-04-13T20:20:08.015151Z"},"trusted":true},"execution_count":43,"outputs":[]}]}